{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "import datetime\n",
    "import re \n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pollution = [\"air #pollution\", \"空气污染\", \"#airpollution\", \"वायु प्रदुषण\", \"la pollution de l'air\", \"la #pollution\",\n",
    "            \"air #pollution\", \"l'air #pollution\", \"वायु प्रदुषण\",'air quality','smog','embouteillage',\"#वायु प्रदुषण\",\"वायु #प्रदूषण\"]\n",
    "climate_change=['changement climatique','#changementclimatique']\n",
    "\n",
    "forest_file = [\"forest fire\", \"forest fires\"]\n",
    "water_flood = [\"water poisoning\", \"water contamination\",\"flood flash\", 'flood water', \"flood warning\"]\n",
    "earthquake  = [\"earthquake\"]\n",
    "oil_spill =     [\"oil spill\", \"pipeline spill\", \"tarsands spill\", \"tankers spill\", \"fossilfuel spill\", \"petroleum spill\"]\n",
    "toxic_mildew = [\"acid rain\", \"toxic rain\", \"mildew home\", \"mildew infested\", \"mildew basement\", \"mildew removal\", \n",
    "                \"mildew growth\", \"mildew inspection\", \"mold flood\", \"mildew flood\"]\n",
    "bug = [\"adelgid\", \"aphid\", \"beetle\", \"earwig\", \"insect\", \"locust\", \"louse\", \"moth\", \"psyllid\", \"termites\",\n",
    "              \"termite bites\", \"bug bites\", \"bugs bites\",\"bed bugs\",\"bug\",\"bugs\"]\n",
    "allergy  = \"\"\"allergy\n",
    "allergins\n",
    "pollen\n",
    "dander\n",
    "allergy + cough\n",
    "allergies + cough\n",
    "pollen + cough\n",
    "dander + cough\n",
    "dust + cough\n",
    "allergy + sneeze\n",
    "allergies + sneeze\n",
    "pollen + sneeze\n",
    "dander + sneeze\n",
    "dust + sneeze\n",
    "allergy + asthma\n",
    "allergies + asthma\n",
    "pollen + asthma\n",
    "dander + asthma\n",
    "dust + asthma\n",
    "allergy + respiratory\n",
    "allergies + respiratory\n",
    "pollen + respiratory\n",
    "dander + respiratory\n",
    "dust + respiratory\n",
    "allergy + lung\n",
    "allergies + lung\n",
    "pollen + lung\n",
    "dander + lung\n",
    "dust + lung\"\"\".split(\"\\n\")\n",
    "allergy = [word.replace(\"+\", \"\") for word in allergy]\n",
    "allergy = [word.replace(\"  \", \" \") for word in allergy]\n",
    "dust = [\"dust\"]\n",
    "pollution_re          = re.compile(r'('+'|'.join(pollution)+')',  re.IGNORECASE)\n",
    "climate_change_re  = re.compile(r'('+'|'.join(climate_change)+')',  re.IGNORECASE)\n",
    "forest_file_re     = re.compile(r'('+'|'.join(forest_file)+')',  re.IGNORECASE)\n",
    "water_flood_re     = re.compile(r'('+'|'.join(water_flood)+')',  re.IGNORECASE)\n",
    "earthquake_re      = re.compile(r'('+'|'.join(earthquake )+')',  re.IGNORECASE)\n",
    "oil_spill_re       = re.compile(r'('+'|'.join(oil_spill)+')',  re.IGNORECASE)\n",
    "bug_re             = re.compile(r'('+'|'.join(bug)+')',  re.IGNORECASE)\n",
    "allergy_re         = re.compile(r'('+'|'.join(allergy)+')',  re.IGNORECASE)\n",
    "dust_re            = re.compile(r'('+'|'.join(dust)+')',  re.IGNORECASE)\n",
    "toxic_mildew_re    = re.compile(r'('+'|'.join(toxic_mildew)+')',  re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_text(tweet):\n",
    "    try:\n",
    "        return(tweet[\"extended_tweet\"][\"full_text\"])\n",
    "    except:\n",
    "        return(tweet[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unified(df):\n",
    "    value_column=['followers_count','statuses_count','listed_count','favourites_count','pollution', 'climate_change', 'forest_file', 'water_flood',\n",
    "       'earthquake', 'oil_spill', 'bug', 'allergy', 'dust', 'toxic_mildew']\n",
    "    other_column=set(userprofile.columns) - set(value_column)\n",
    "    # for non value column we only select one \n",
    "    part_a = df.loc[df.id.drop_duplicates().index]  # index\n",
    "    part_a.drop(columns=value_column,inplace=True)\n",
    "    # for value column we select the max\n",
    "    part_b=df.groupby(['id'])[value_column].max()\n",
    "    part_b.reset_index(inplace=True)\n",
    "    # combine both part\n",
    "    assert(part_a.shape[0]==part_b.shape[0])\n",
    "    mydf=part_a.merge(part_b,on=['id'])\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__== \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='get user profile')\n",
    "    parser.add_argument('path',metavar='I',type= str, help ='input json path output/**.p ')\n",
    "    parser.add_argument('savename',metavar='S',type=str,help='saved name for file')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    with open(args.path,mode='br') as f:\n",
    "        placejson=pickle.load(f,encoding='utf-8')\n",
    "    userattribute = [attribute for attribute in set(placejson[0]['user'])]\n",
    "    \n",
    "    userprofile=pd.DataFrame()\n",
    "    for attribute in tqdm(userattribute):\n",
    "        userprofile[attribute] = list(map(lambda thistweet: thistweet['user'][attribute] if attribute in thistweet['user'].keys() else None,placejson))\n",
    "    \n",
    "    userprofile['text']=list(map(lambda tweet: get_full_text(tweet), placejson))\n",
    "    \n",
    "    \n",
    "    print(\"going to get tweet feature for each user\")\n",
    "    with tqdm(total =100) as pbar:\n",
    "        userprofile['pollution'] = list(map(lambda tweet: True if pollution_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "        userprofile['climate_change'] = list(map(lambda tweet: True if climate_change_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "        userprofile['forest_file'] = list(map(lambda tweet: True if forest_file_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "        userprofile['water_flood'] = list(map(lambda tweet: True if water_flood_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "        userprofile['earthquake'] = list(map(lambda tweet: True if earthquake_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "        userprofile['oil_spill'] = list(map(lambda tweet: True if oil_spill_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "        userprofile['bug'] = list(map(lambda tweet: True if bug_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "        userprofile['allergy'] = list(map(lambda tweet: True if allergy_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "        userprofile['dust'] = list(map(lambda tweet: True if dust_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "        userprofile['toxic_mildew'] = list(map(lambda tweet: True if toxic_mildew_re.search(tweet) else False,userprofile.text))\n",
    "        pbar.update(10)\n",
    "    \n",
    "    \n",
    "    userprofile.drop(columns=['id_str'],inplace=True)\n",
    "    userprofile.drop_duplicates(inplace=True)\n",
    "    datetime.datetime.strptime('Tue May 05 15:58:46 +0000 2009','%a %b %d %H:%M:%S %z %Y')\n",
    "    userprofile['created_at']=list(map(lambda time: datetime.datetime.strptime(time,'%a %b %d %H:%M:%S %z %Y'),userprofile.created_at))\n",
    "    \n",
    "    userprofile_clean=get_unified(userprofile)\n",
    "    userprofile_clean.to_csv(\"output/{}.csv\".format(args.savename).,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

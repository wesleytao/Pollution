{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "from datetime import datetime\n",
    "import time\n",
    "from __future__ import print_function\n",
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckey = 'NdQdQm2OALKTJgtCr9mz8SEAK'\n",
    "csecret= '2GVLXTHcIy3htHqD5NEIX1IGVuTNjiHMHNEXT2OTTlvjP50hKw'\n",
    "atoken= '980527124133109766-R2NKGIqJjrUvkOALRw7bdzAHRa4FV18'\n",
    "asecret= 'r5Px3c5gLtXVuNjJI53qoImV1PW6CeXwRyv8gnjqwTzt0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # wesley\n",
    "# ckey = 'NdQdQm2OALKTJgtCr9mz8SEAK'\n",
    "# csecret= '2GVLXTHcIy3htHqD5NEIX1IGVuTNjiHMHNEXT2OTTlvjP50hKw'\n",
    "# atoken= '980527124133109766-R2NKGIqJjrUvkOALRw7bdzAHRa4FV18'\n",
    "# asecret= 'r5Px3c5gLtXVuNjJI53qoImV1PW6CeXwRyv8gnjqwTzt0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keran\n",
    "# ckey = 'ok5bMdzCP7UMJMZUMm9tLZdtg'\n",
    "# csecret= 'J9V0m78943Q4dDzQGzOiSpVWex2H1rjSRR5TCAQ2g5zUt7m0Gm'\n",
    "# atoken= '980478205151842304-TQ8AWkaDSh5XtLvsa2hyWfAJONcdHxp'\n",
    "# asecret= 'SbH7zQJnFdQRF6qzUv1BWaUgAjksGdrPdnOGB2Ft8vByl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user=[\"@BeijingAir\"]\n",
    "original=[\"air #pollution\",\"空气污染\",\"#airpollution\",\"वायु प्रदुषण\",\"la pollution de l'air\",\"la #pollution\",\"air #pollution\",\"l'air #pollution\",\"वायु प्रदुषण\"]\n",
    "category_1=[\"forest fire\",\"forest fires\"]\n",
    "category_2=[\"water poisoning\",\"water contamination\"]\n",
    "category_3=[\"flood flash\",\"flood water\",\"flood warning\"]\n",
    "category_4=[\"earthquake\"]\n",
    "category_5=[\"oil spill\",\"pipeline spill\",\"tarsands spill\",\"tankers spill\", \"fossilfuel spill\",\"petroleum spill\"]\n",
    "category_6=[\"acid rain\",\"toxic rain\",\"mildew home\",\"mildew infested\",\"mildew basement\",\"mildew removal\",\"mildew growth\",\"mildew inspection\",\"mold flood\",\"mildew flood\"]\n",
    "category_7=[\"adelgid\",\"aphid\",\"beetle\",\"earwig\",\"insect\",\"locust\",\"louse\",\"moth\",\"psyllid\",\"termites\",\"termite bites\",\"bugs\",\"bug\",\"bug bites\",\"bugs bites\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_8=\"\"\"allergy\n",
    "allergins\n",
    "pollen\n",
    "dander\n",
    "dust\n",
    "allergy + cough\n",
    "allergins + cough\n",
    "pollen + cough\n",
    "dander + cough\n",
    "dust + cough\n",
    "allergy + sneeze\n",
    "allergins + sneeze\n",
    "pollen + sneeze\n",
    "dander + sneeze\n",
    "dust + sneeze\n",
    "allergy + asthma\n",
    "allergins + asthma\n",
    "pollen + asthma\n",
    "dander + asthma\n",
    "dust + asthma\n",
    "allergy + respiratory\n",
    "allergins + respiratory\n",
    "pollen + respiratory\n",
    "dander + respiratory\n",
    "dust + respiratory\n",
    "allergy + lung\n",
    "allergins + lung\n",
    "pollen + lung\n",
    "dander + lung\n",
    "dust + lung\"\"\".split(\"\\n\")\n",
    "category_8=[word.replace(\"+\",\"\") for word in category_8]\n",
    "category_8=[word.replace(\"  \",\" \") for word in category_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# category_17=[\"@beijingair\"]\n",
    "category_9=[\"dust\"]\n",
    "category_10=[\"bed bugs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywordlist= user +original+category_1+category_2+category_3+category_4+category_5+category_6+category_7+category_8+category_9+category_10\n",
    "# keywordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONGO_HOST= 'mongodb://localhost/twitterdb'  # assuming you have mongoDB installed locally\n",
    "                                             # and a database called 'twitterdb'\n",
    "WORDS = keywordlist\n",
    "client = MongoClient()\n",
    "# Use twitterdb database. If it doesn't exist, it will be created.\n",
    "db = client.twitterdb\n",
    "filepath=\"../data/duplicate.json\"\n",
    "class StreamListener(tweepy.StreamListener):    \n",
    "    #This is a class provided by tweepy to access the Twitter Streaming API. \n",
    "\n",
    "    def on_connect(self):\n",
    "        # Called initially to connect to the Streaming API\n",
    "        print(\"You are now connected to the streaming API.\")\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        # On error - if an error occurs, display the error / status code\n",
    "        print('An Error has occured: ' + repr(status_code))\n",
    "        return False\n",
    "\n",
    "    def on_data(self, data):\n",
    "        #This is the meat of the script...it connects to your mongoDB and stores the tweet\n",
    "        try:\n",
    "#                 client = MongoClient(MONGO_HOST)\n",
    "\n",
    "\n",
    "            # Decode the JSON from Twitter\n",
    "            datajson = json.loads(data)\n",
    "\n",
    "            #use tweet id as mongodb id\n",
    "            datajson[\"_id\"] = datajson.pop(\"id\")\n",
    "\n",
    "            #grab the 'created_at' data from the Tweet to use for display\n",
    "            created_at = datajson['created_at']\n",
    "\n",
    "            #print out a message to the screen that we have collected a tweet\n",
    "#             print(\"Tweet collected at \" + str(created_at))\n",
    "\n",
    "            #insert the data into the mongoDB into a collection called twitter_search\n",
    "            #if twitter_search doesn't exist, it will be created.\n",
    "            db.twitter_search.insert_one(datajson)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            with open(filepath,\"a\") as f:\n",
    "                f.write(data)\n",
    "                \n",
    "\n",
    "auth = tweepy.OAuthHandler(ckey, csecret)\n",
    "auth.set_access_token(atoken, asecret)\n",
    "#Set up the listener. The 'wait_on_rate_limit=True' is needed to help with Twitter API rate limiting.\n",
    "listener = StreamListener(api=tweepy.API(wait_on_rate_limit=True)) \n",
    "streamer = tweepy.Stream(auth=auth, listener=listener)\n",
    "print(\"Tracking: \" + str(WORDS))\n",
    "streamer.filter(track=WORDS,follow=\"15527964\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(streamer.filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

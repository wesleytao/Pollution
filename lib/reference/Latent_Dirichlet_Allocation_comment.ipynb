{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "support_or_not=pd.read_csv('../output/data_with_vadersentiment.csv',encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_status_user_name</th>\n",
       "      <th>retweet_status_follower_count</th>\n",
       "      <th>retweet_status_favorite_count</th>\n",
       "      <th>retweet_status_retweet_count</th>\n",
       "      <th>retweet_status_reply_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>980822559901016070</td>\n",
       "      <td>Here â€™ full list American goods affected China â€™ retaliatory tariffs #create</td>\n",
       "      <td>26558316</td>\n",
       "      <td>blackwhalegroup</td>\n",
       "      <td>335</td>\n",
       "      <td>NYC SD KC</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-02 15:01:35</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>980822563679911937</td>\n",
       "      <td>Hope he's ready give aid farmers He'll probably wait Willy Nelson others hold concerts â€¦</td>\n",
       "      <td>1525168716</td>\n",
       "      <td>Donna</td>\n",
       "      <td>457</td>\n",
       "      <td>california</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-02 15:01:36</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.6597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>980822565378838531</td>\n",
       "      <td>RT @RedTRaccoon NC pay high price metals tariffs North Carolina also get hit massive 25 tariff pork As stat â€¦</td>\n",
       "      <td>1148610157</td>\n",
       "      <td>American AntiFed</td>\n",
       "      <td>16431</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>en</td>\n",
       "      <td>9.808189e+17</td>\n",
       "      <td>...</td>\n",
       "      <td>Red T Raccoon</td>\n",
       "      <td>97822.0</td>\n",
       "      <td>9.808189e+17</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-04-02 15:01:37</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>980822567316590593</td>\n",
       "      <td>RT @MelissaLeeCNBC Tariff impact data already THERE WERE A LOT OF GENERAL CONCERNS ABOUT TARIFFS IN U S FACTORY ACTIVITY REPORT IN M â€¦</td>\n",
       "      <td>601305639</td>\n",
       "      <td>Don Juan de Morocco</td>\n",
       "      <td>196</td>\n",
       "      <td>Internet</td>\n",
       "      <td>en</td>\n",
       "      <td>9.808139e+17</td>\n",
       "      <td>...</td>\n",
       "      <td>Melissa Lee</td>\n",
       "      <td>87491.0</td>\n",
       "      <td>9.808139e+17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-04-02 15:01:37</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>980822568281235456</td>\n",
       "      <td>The full list 128 US products targeted China â€™ retaliatory tariffs @qz @realDonaldTrump @GOP @SenateGOP</td>\n",
       "      <td>2279225400</td>\n",
       "      <td>Gloria (Dem) ðŸŒŠðŸ‡ºðŸ‡¸ðŸŒŠ</td>\n",
       "      <td>14158</td>\n",
       "      <td>New York USA</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-04-02 15:01:37</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1                  id  \\\n",
       "0  0           0             980822559901016070   \n",
       "1  1           1             980822563679911937   \n",
       "2  2           2             980822565378838531   \n",
       "3  3           3             980822567316590593   \n",
       "4  4           4             980822568281235456   \n",
       "\n",
       "                                                                                                                                     text  \\\n",
       "0  Here â€™ full list American goods affected China â€™ retaliatory tariffs #create                                                             \n",
       "1  Hope he's ready give aid farmers He'll probably wait Willy Nelson others hold concerts â€¦                                                 \n",
       "2  RT @RedTRaccoon NC pay high price metals tariffs North Carolina also get hit massive 25 tariff pork As stat â€¦                            \n",
       "3  RT @MelissaLeeCNBC Tariff impact data already THERE WERE A LOT OF GENERAL CONCERNS ABOUT TARIFFS IN U S FACTORY ACTIVITY REPORT IN M â€¦   \n",
       "4  The full list 128 US products targeted China â€™ retaliatory tariffs @qz @realDonaldTrump @GOP @SenateGOP                                  \n",
       "\n",
       "      user_id            user_name  user_followers      user_loc lang  \\\n",
       "0  26558316    blackwhalegroup      335             NYC SD KC     en    \n",
       "1  1525168716  Donna                457             california    en    \n",
       "2  1148610157  American AntiFed     16431           New Mexico    en    \n",
       "3  601305639   Don Juan de Morocco  196             Internet      en    \n",
       "4  2279225400  Gloria (Dem) ðŸŒŠðŸ‡ºðŸ‡¸ðŸŒŠ    14158           New York USA  en    \n",
       "\n",
       "     retweet_id    ...     retweet_status_user_name  \\\n",
       "0 NaN              ...     NaN                        \n",
       "1 NaN              ...     NaN                        \n",
       "2  9.808189e+17    ...     Red T Raccoon              \n",
       "3  9.808139e+17    ...     Melissa Lee                \n",
       "4 NaN              ...     NaN                        \n",
       "\n",
       "  retweet_status_follower_count  retweet_status_favorite_count  \\\n",
       "0 NaN                           NaN                              \n",
       "1 NaN                           NaN                              \n",
       "2  97822.0                       9.808189e+17                    \n",
       "3  87491.0                       9.808139e+17                    \n",
       "4 NaN                           NaN                              \n",
       "\n",
       "   retweet_status_retweet_count  retweet_status_reply_count  \\\n",
       "0 NaN                           NaN                           \n",
       "1 NaN                           NaN                           \n",
       "2  30.0                          5.0                          \n",
       "3  3.0                           1.0                          \n",
       "4 NaN                           NaN                           \n",
       "\n",
       "            created_at    neg    neu   pos  compound  \n",
       "0  2018-04-02 15:01:35  0.151  0.849  0.00 -0.1531    \n",
       "1  2018-04-02 15:01:36  0.000  0.690  0.31  0.6597    \n",
       "2  2018-04-02 15:01:37  0.072  0.928  0.00 -0.1027    \n",
       "3  2018-04-02 15:01:37  0.000  1.000  0.00  0.0000    \n",
       "4  2018-04-02 15:01:37  0.000  1.000  0.00  0.0000    \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_or_not.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hope he's ready give aid farmers He'll probably wait Willy Nelson others hold concerts\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_or_not.text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean stop words like @ and other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    " \n",
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # @-mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hash-tags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess(s, lowercase=False):\n",
    "    tokens = tokenize(s)\n",
    "#     print(tokens_re.search(tokens[0]))\n",
    "    if lowercase:\n",
    "        tokens =  [token if emoticon_re.search(token)  else token.lower() for token in tokens]\n",
    "    return tokens\n",
    "tweet = 'RT @marcobonzanini: just an example! :D http://example.com #NLP'\n",
    "print(preprocess(tweet))\n",
    "# ['RT', '@marcobonzanini', ':', 'just', 'a n', 'example', '!', ':D', 'http://example.com', '#NLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT', '@marcobonzanini', ':', 'just', 'an', 'example', '!', ':D', 'http://example.com', '#NLP']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "def remove_stop_words(tweet):\n",
    "    out=tweet\n",
    "    if(tweet):\n",
    "        p=re.compile(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+') # URLs\n",
    "        p2=re.compile(r'(?:@[\\w_]+)')\n",
    "        punctuation = list(string.punctuation)\n",
    "        stop = stopwords.words('english') + punctuation + ['via',\"\\r\",r'<[^>]+>',\"RT\",\"â€¦\",\"â€™\",\"â€”\",\"u\"]+[r'(?:@[\\w_]+)']\n",
    "    #     print(stop)\n",
    "        terms_stop = [term for term in preprocess(tweet) if p.match(term)==None and term not in stop and p2.match(term)==None]\n",
    "    #     terms_stop = [term for term in preprocess(tweet) if term not in stop]\n",
    "        out=\" \".join(terms_stop)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here full list American goods affected China retaliatory tariffs'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words(support_or_not[\"text\"][11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here â€™ full list American goods affected China â€™ retaliatory tariffs'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_or_not[\"text\"][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mytext=list(map(lambda tweet: remove_stop_words(tweet), support_or_not.text))\n",
    "support_or_not.text=mytext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_threshold=0.1\n",
    "neg_threshold=-0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_list=list(support_or_not.loc[support_or_not[\"compound\"]>=pos_threshold].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_list=list(support_or_not.loc[support_or_not[\"compound\"]<=neg_threshold].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "    \n",
    "# create sample documents\n",
    "# doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "# doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "# doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "# doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "# doc_e = \"Health professionals say that brocolli is good for your health.\" \n",
    "\n",
    "# compile sample documents into a list\n",
    "# doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]\n",
    "doc_set=positive_list\n",
    "# list for tokenized documents in loop\n",
    "texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "    \n",
    "# convert tokenized documents into a document-term matrix\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate LDA model\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=2, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.024*\"tariff\" + 0.020*\"trade\" + 0.018*\"trump\" + 0.014*\"china\" + 0.014*\"s\" + 0.011*\"war\" + 0.011*\"increas\" + 0.007*\"win\" + 0.007*\"agricultur\" + 0.007*\"presid\" + 0.007*\"good\"'), (1, '0.076*\"2\" + 0.075*\"car\" + 0.074*\"sent\" + 0.054*\"state\" + 0.050*\"unit\" + 0.043*\"1\" + 0.043*\"china\" + 0.042*\"tariff\" + 0.037*\"paid\" + 0.037*\"trump\" + 0.037*\"chin\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=10, num_words=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China hits United States tariffs 3 billion exports'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic(list_document,num_topics):\n",
    "    \"\"\"list_document is a list of string , each element is a document\"\"\"\n",
    "    num_topics=num_topics\n",
    "    doc_clean = [clean(doc).split() for doc in list_document] \n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "    ldamodel = Lda(doc_term_matrix, num_topics=num_topics, id2word = dictionary, passes=50)\n",
    "    mylist=[]\n",
    "    for topic in range(num_topics):\n",
    "        termlist=ldamodel.print_topics(num_topics=num_topics, num_words=10)[topic][1].split(\"+\")\n",
    "        mylist.append(list(map(lambda term:term.split(\"*\"),termlist)))\n",
    "    pandas_list=[]\n",
    "    for topic_index in range(num_topics):\n",
    "        this_topic=pd.DataFrame(mylist[topic_index],columns=[\"prob\",\"key_words\"])\n",
    "        this_topic[\"topic\"]=topic_index\n",
    "        pandas_list.append(this_topic)\n",
    "    LDA_result=pd.concat(pandas_list)\n",
    "    return(LDA_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_topic_dataframe=topic(positive_list,num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_topic_dataferame=topic(negative_list,num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_topic_dataferame.to_csv(\"negative_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_topic_dataframe.to_csv(\"positive_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topic(list_document,num_topics):\n",
    "    \"\"\"list_document is a list of string , each element is a document\"\"\"\n",
    "    num_topics=num_topics\n",
    "    doc_clean = [clean(doc).split() for doc in list_document] \n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    Lda = gensim.models.ldamodel.LdaModel\n",
    "    ldamodel = Lda(doc_term_matrix, num_topics=num_topics, id2word = dictionary, passes=50)\n",
    "    return(ldamodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_model=topic(positive_list,num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"../output/positve_model.pickle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(path, 'bw') as f:\n",
    "    pickle.dump(positive_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Wesley_Tao\\6.Software\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "for t in range(positive_model.num_topics):\n",
    "    plt.figure()\n",
    "    plt.imshow(WordCloud(background_color='white').fit_words(dict(positive_model.show_topic(t, 200))))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Positive Topic \" )\n",
    "    plt.savefig('../fig/positivefig'+str(t)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "negative_model=topic(negative_list,num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Wesley_Tao\\6.Software\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "for t in range(negative_model.num_topics):\n",
    "    plt.figure()\n",
    "    plt.imshow(WordCloud(background_color='white').fit_words(dict(negative_model.show_topic(t, 200))))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Negative Topic\" )\n",
    "    plt.savefig('../fig/negativefig'+str(t)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"../output/negative_model.pickle\"\n",
    "with open(path, 'bw') as f:\n",
    "    pickle.dump(negative_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

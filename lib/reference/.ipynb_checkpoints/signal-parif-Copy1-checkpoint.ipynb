{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pandas import Index\n",
    "import matplotlib.pyplot as plt\n",
    "from pytrends.request import TrendReq\n",
    "from pytrends import request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_process(table,event_var='PM25_Marseille_Longchamp',event_threshold = 40, duration = 6,var_name_list='air pollution'):\n",
    "    \"\"\"Find the spike in pm25 and plot a sliding window for google trend \"\"\"\n",
    "\n",
    "    index_list=np.where(table[event_var]>event_threshold)[0]\n",
    "    \n",
    "    # add first element\n",
    "    shrink_index_list = [index_list[0]]\n",
    "    date_set ={table.date[index_list[0]]}\n",
    "    \n",
    "    # exclude for the same day\n",
    "    for cnt in range(1,len(index_list)):\n",
    "        if table.date[index_list[cnt]] in date_set:\n",
    "            pass\n",
    "        else:\n",
    "            shrink_index_list.append(index_list[cnt].copy())\n",
    "            date_set.add(table.date[index_list[cnt]])\n",
    "    \n",
    "    bind_list = []\n",
    "    for start_index in shrink_index_list:\n",
    "        this_sequence = table.loc[range(start_index-2,start_index+duration),\n",
    "                                  var_name_list]\n",
    "        start_date = table.datetime[start_index]\n",
    "        tuples = list(zip([start_date]*(duration+2),range(-2,duration)))\n",
    "\n",
    "        this_sequence.index = pd.MultiIndex.from_tuples(tuples,names=['event_date_index','hour_index'])\n",
    "    #         this_sequence = (this_sequence- this_sequence.mean())/this_sequence.std()\n",
    "\n",
    "        bind_list.append(this_sequence)\n",
    "    new_table=pd.concat(bind_list)     \n",
    "    \n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetching_trend(airdata, kw_list,location_code='FR-U',timezone = 0):\n",
    "    input_table = airdata\n",
    "    newest_datetime   = max(input_table['datetime'])\n",
    "    earliest_datetime = min(input_table['datetime'])\n",
    "    pytrends = TrendReq(hl='En-US', tz=timezone)\n",
    "    print(\"fectching trend \")\n",
    "    ggtrend_list =[]\n",
    "    for keyword in kw_list:\n",
    "        \n",
    "        this_list = [keyword]\n",
    "        try: \n",
    "            topic_code = pytrends.suggestions(keyword)[0]['mid']\n",
    "            this_list.append(topic_code)\n",
    "        except IndexError:\n",
    "            pass\n",
    "            \n",
    "        ggtrend = pytrends.get_historical_interest(this_list, \n",
    "                                 year_start=earliest_datetime.year,\n",
    "                                          month_start=earliest_datetime.month, \n",
    "                                          day_start=earliest_datetime.days_in_month, \n",
    "                                          hour_start=earliest_datetime.hour, \n",
    "                                 year_end=newest_datetime.year,\n",
    "                                          month_end=newest_datetime.month, \n",
    "                                          day_end=newest_datetime.days_in_month, \n",
    "                                          hour_end=newest_datetime.hour, \n",
    "                                 cat=0, # all categorical\n",
    "                                          geo=location_code,  # Provence-Alpes-Côte d'Azur\n",
    "                                          gprop='',  # no specific group # image #hastag etc\n",
    "                                          sleep=0)\n",
    "        ggtrend.columns= Index([keyword, keyword+\" topic\", 'isPartial'], dtype='object')\n",
    "        ggtrend_list.append(ggtrend)\n",
    "    print(\"trend is fectched\")\n",
    "    return ggtrend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parca_table= pd.read_csv(\"../stage/parif.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parca_table['datetime']=parca_table['datetime'].apply(lambda string: datetime.strptime(string,'%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date_time = pd.date_range(parca_table[['datetime']].min()[0],parca_table[['datetime']].max()[0],freq='H')\n",
    "full_time_set = set(map(lambda mytime: mytime.strftime(\"%Y-%m-%d %H:%M:%S\"),full_date_time.to_series())) \n",
    "data_time_set = set(map(lambda timestamp: str(timestamp),parca_table['datetime']))\n",
    "    # pad na values\n",
    "if len(full_time_set) != len(data_time_set):\n",
    "    pad_time = full_time_set -data_time_set\n",
    "    pad_table = pd.DataFrame()\n",
    "    pad_table['datetime']=[datetime.strptime(mytime,\"%Y-%m-%d %H:%M:%S\") for mytime in pad_time]\n",
    "    for column in parca_table.columns:\n",
    "        if column !=\"datetime\":\n",
    "            pad_table[column]=None\n",
    "    parca_table = pd.concat([parca_table,pad_table],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching google trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2017-01-01 00:00:00', '2017-01-01 01:00:00',\n",
       "               '2017-01-01 02:00:00', '2017-01-01 03:00:00',\n",
       "               '2017-01-01 04:00:00', '2017-01-01 05:00:00',\n",
       "               '2017-01-01 06:00:00', '2017-01-01 07:00:00',\n",
       "               '2017-01-01 08:00:00', '2017-01-01 09:00:00',\n",
       "               ...\n",
       "               '2018-08-18 14:00:00', '2018-08-18 15:00:00',\n",
       "               '2018-08-18 16:00:00', '2018-08-18 17:00:00',\n",
       "               '2018-08-18 18:00:00', '2018-08-18 19:00:00',\n",
       "               '2018-08-18 20:00:00', '2018-08-18 21:00:00',\n",
       "               '2018-08-18 22:00:00', '2018-08-18 23:00:00'],\n",
       "              dtype='datetime64[ns]', length=14280, freq='H')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "KW_LIST= ['difficultés respiratoires',\n",
    "          'difficulté à respirer',\n",
    "          'asthme',\n",
    "          'difficulté pour respirer',\n",
    "          'sensation d’étouffement',\n",
    "          'dyspnée',\n",
    "          'spasmophilie',\n",
    "          'nuage de pollution',\n",
    "          'saleté de l’air',\n",
    "          'particules nocives',\n",
    "          'respiration',\n",
    "          'maladies respiratoires',\n",
    "          'pollution de l’air',\n",
    "          'pollution atmosphérique',\n",
    "          'pollution',\n",
    "          'Masque', #mask\n",
    "          \"Purificateur d'air\", #air purifier\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION_CODE = 'FR-J'  # for Île-de-France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fectching trend \n"
     ]
    }
   ],
   "source": [
    "ggtrend_list = fetching_trend(parca_table,kw_list=KW_LIST,location_code=LOCATION_CODE,timezone = 0)\n",
    "ggtrend=pd.concat(ggtrend_list,axis=1)\n",
    "ggtrend.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_t=parca_table.merge(ggtrend,left_on='datetime',right_on='date')\n",
    "kw_str  =\"_\".join(KW_LIST)\n",
    "merged_t.to_csv(\"../stage/parif_{}_{}.csv\".format(kw_str,parca_table.columns[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_table=signal_process(merged_t,event_var='PA04C_PM25',event_threshold = 35,duration = 12,var_name_list=list(ggtrend.columns)+['PA04C_PM25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_table.groupby(\"hour_index\").mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_table.to_csv(\"../output/air_parif_threshold_35_colsum_duration_12H.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
